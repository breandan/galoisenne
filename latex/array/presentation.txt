Talk notes


First, the bad news
   - Two problems: human complexity of type-level programming and computational complexity.
   - Types were never supposed to perform arbitrary computation
      - Types are designed to quickly over-approximate admissible programs (and deterministically halt).
      - We know from Church that Turing-equivalent systems (e.g., Î»-calculus) are undecidable
      - We know from Rice that any nontrivial property of a universal PL is undecidable
      - Even bounded-length Turing machines are physically impossible:
          - There exist length-5 Busy beavers which require galactic computation to decide
      - Types ought to terminate, otherwise they are just computation with extra steps
      - Undecidable type systems are just esoteric programming languages
   - Designing type systems is hard, requires highly-specialized knowledge
      - Java language designers spent 10 years designing generics
      - Some of the brightest minds in Sun -- and they still got it wrong!

Now the good news!
   - Worst-case complexity appears to be relatively scarce in actual programs
   - In practice, we know that typing works, and usually terminates quickly
   - Turing Machines are spherical cows: a fictitious thought experiment
   - All physically-realizable machines are somewhere between regular and context-sensitive
   - This restricts expressiveness, but *not as much as you might think*
   - Grammars allow us to encode a huge amount of information in a finite space
   - Before there were such things as type systems, there were parsers
   - Type systems are "just" parsers repackaged in a fancy notation
   - I would argue the goal of the parser is first and foremost to reject inadmissable programs.
   - In this talk, I am going to make an argument for type checking in the parser.
   - Three advantages: computational complexity, ease of design and theoretical elegance

Annotated history of types
   - Types can encode simple state machines (give some examples)
   - Context free languages can be encoded straightforwardly in Java's type system
   - We can still approximate dependently typed programming! (this work)

Why matrix-based parsing?
   - Sketch-based synthesis can be reduced to algebraic rootfinding
   - Opens up a compilation pathway to linear algebraic techniques
   - Abstract algebra gives us access to an ancient (500+ YO) knowledge base
   - SPGEMMs can be evaluated on GPUs and ASICs very efficiently
   - Subcubic multiplication algorithm (asymptotic optimality!)
   - Boolean matrices are easily compilable to SAT solving
   - Parallel type checking: we can compile types directly to circuits
   - Lots of interesting research about discrete derivatives (PwD)
   - Galois theory has deep connections to cryptography & ProbProg
   - Reversible: we can go "forward", i.e., infer holes in code or "backward", i.e., solve for specification
   - Many interesting possibilities for program synthesis!