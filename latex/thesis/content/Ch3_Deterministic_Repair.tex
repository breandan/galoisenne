\chapter{\rm\bfseries Deterministic Program Repair}
\label{ch:chapter02}

Parsimony is a guiding principle in program repair that comes from the 14th century Fransiscan friar named William of Ockham. In keeping with the Fransiscan minimalist lifestyle, Ockham's principle basically says that when you have multiple hypotheses, the simplest one is the best. It is not precisely clear what ``simple'' ought to mean in the context of program repair, but a first-order approximation is to strive for the smallest number of changes required to transform an invalid program into a valid one.

Levenshtein distance is one such metric for measuring the minimum number of changes between two strings. First proposed by the Soviet scientist Vladimir Levenshtein, it quantifies how many insertions, deletions, and substitutions are required to transform one string into another. Conveniently, there is an automaton, called the Levenshtein automaton~\cite{schulz2002fast}, that recognizes all strings within a given edit distance of a given string. We can use this automaton to locate the positions and contents of the most likely repair consistent with the observed program and the grammar.

The closure of CFLs under intersection with regular languages was first established in 1961 by Bar-Hillel, implying the existence of a context-free grammar representing the conjunction of any finite automaton and context-free grammar. Such a construction was given by Salomaa in 1973, who provides a direct, but inefficient, construction. In our work, we refine this construction to intersections with Levenshtein automata, which recognize all and only strings within a given edit distance of a reference string. Using this refinement, we demonstrate it is feasible to repair multiline syntax errors in practical programming languages.

\begin{wrapfigure}{r}{0.4\textwidth}
  \vspace{-0.2cm}
  \input{content/figures/cfl_intersect}
  \vspace{-0.3cm}
  \caption{CFL intersection with the local edit region of a given broken code snippet.}
  \vspace{-0.2cm}
\end{wrapfigure}

Given the source code for a computer program $\err\sigma$ and a grammar $G$, our goal is to find every valid string $\sigma$ consistent with the grammar $G$ and within a certain edit distance, $d$. Consider the language of valid strings within a given Levenshtein distance from a reference string $\err\sigma$. We can intersect the language given by the Levenshtein automaton with the language of all valid programs given by the grammar $G$. The resulting language, $\mathcal{L}(G_\cap)$ will contain every repair within the designated edit distance.

\section{Levenshtein automata}

Levenshtein automata are finite automata that recognize all and only strings within a given edit distance of another string by permitting insertions, deletions, and substitutions. For instance, suppose we have the input, \texttt{( ) )}, and wish to find nearby or parsimonious edits. To represent the language of parsimonious edits, we can construct the Levenshtein-1 automaton accepting every string that can be formed by inserting, substituting or deleting a single parenthesis. We depict this automaton in Figure~\ref{fig:lev_automaton}.

\begin{figure}[h!]
  \input{content/figures/lev1_simp}
  \caption{Automaton recognizing every 1-edit patch. We nominalize the original automaton, ensuring upward arcs denote a mutation, and use a symbolic predicate, which deduplicates parallel arcs in large alphabets.}\label{fig:lev_automaton}\vspace{-5pt}
\end{figure}

The original automaton is nondeterministic, containing an upward arc for each token. This can be avoided with a simple modification that matches an inequality predicate. The machine enters at $q_{0, 0}$ and at each step, accepts the labeled token. Final states are encircled twice, denoting that any trajectory ending at such a state is considered valid.
When the edit distance grows larger, we introduce some additional arcs to handle multi-token deletions, but the overall picture remains unchanged. We depict a 3x5 automaton recognizing 3-edit patches of a length-5 string in Figure~\ref{fig:lev_nfa}.

\begin{figure}%{r}{0.4\textwidth}
  \begin{center}
    \input{content/figures/nfa_cfg}
  \end{center}
  \caption{NFA recognizing Levenshtein $L(\sigma: \Sigma^5, 3)$.}\label{fig:lev_nfa}
\end{figure}

Here, a pattern begins to emerge: the automaton is a grid of states, with each horizontal arc consuming a token in the original string, and upwards arcs recognizing mutations. Traversing a vertical arc corresponds to an insertion or substitution, and a diagonal arc corresponds to a deletion. Levenshtein automata can also be defined as a set of inference rules, which generalize this picture to arbitrary length strings and edit distances. The indices are a bit finicky, but the rules are otherwise straightforward.

\begin{prooftree}
  \AxiomC{$s\in\Sigma \phantom{\land} i \in [0, n] \phantom{\land} j \in [1, d_{\max}]$}
  \RightLabel{$\duparrow$}
  \UnaryInfC{$(q_{i, j-1} \overset{s}{\rightarrow} q_{i,j}) \in \delta$}
  \DisplayProof
  \hskip 1.5em
  \AxiomC{$s\in\Sigma \phantom{\land} i \in [1, n] \phantom{\land} j \in [1, d_{\max}]$}
  \RightLabel{$\ddiagarrow$}
  \UnaryInfC{$(q_{i-1, j-1} \overset{s}{\rightarrow} q_{i,j}) \in \delta$}
\end{prooftree}
\begin{prooftree}
  \AxiomC{$i \in [1, n] \phantom{\land} j \in [0, d_{\max}]$}
  \RightLabel{$\drightarrow$}
  \UnaryInfC{$(q_{i-1, j} \overset{\sigma_i}{\rightarrow} q_{i,j}) \in \delta$}
  \DisplayProof
  \hskip 1.5em
  \AxiomC{$d \in [1, d_{\max}] \phantom{\land} i \in [d + 1, n] \phantom{\land} j \in [d, d_{\max}]$}
  \RightLabel{$\knightarrow$}
  \UnaryInfC{$(q_{i-d-1, j-d} \overset{\sigma_i}{\rightarrow} q_{i,j}) \in \delta$}
\end{prooftree}
\begin{prooftree}
  \AxiomC{$\vphantom{|}$}
  \RightLabel{$\textsc{Init}$}
  \UnaryInfC{$q_{0,0} \in I$}
  \DisplayProof
  \hskip 1.5em
  \AxiomC{$q_{i, j} \in Q$}
  \AxiomC{$|n-i+j| \leq d_{\max}$}
  \RightLabel{$\textsc{Done}$}
  \BinaryInfC{$q_{i, j}\in F$}
\end{prooftree}


\newcommand{\substitutionExample}{
  \tikz{
    \foreach \x in {0,8,16,24,32,40}{
      \fill (\x pt,0pt) circle [radius = 1pt];
      \fill (\x pt,8pt) circle [radius = 1pt];
    }
    \phantom{\fill (0pt,-8pt) circle [radius = 1pt];}
    \draw [-to] (0pt,0pt) -- (8pt,0pt);
    \draw [-to] (8pt,0pt) -- (16pt,0pt);
    \draw [-to] (16pt,0pt) -- (24pt,8pt);
    \draw [-to] (24pt,8pt) -- (32pt,8pt);
    \draw [-to] (32pt,8pt) -- (40pt,8pt);
  }
}

\newcommand{\insertionExample}{
  \tikz{
    \foreach \x in {0,8,16,24,32,40}{
      \fill (\x pt,0pt) circle [radius = 1pt];
      \fill (\x pt,8pt) circle [radius = 1pt];
    }
    \phantom{\fill (0pt,-8pt) circle [radius = 1pt];}
    \fill[white] (16pt,0pt) circle [radius = 1.2pt];
    \fill[white] (24pt,8pt) circle [radius = 1.2pt];
    \draw [-to] (0pt,0pt) -- (8pt,0pt);
    \draw [-to] (8pt,0pt) -- (24pt,0pt);
    \draw [-to] (24pt,0pt) -- (16pt,8pt);
    \draw [-to] (16pt,8pt) -- (32pt,8pt);
    \draw [-to] (32pt,8pt) -- (40pt,8pt);
  }
}

\newcommand{\deletionExample}{
  \tikz{
    \foreach \x in {0,8,16,24,32,40}{
      \fill (\x pt,0pt) circle [radius = 1pt];
      \fill (\x pt,8pt) circle [radius = 1pt];
    }
    \phantom{\fill (0pt,-8pt) circle [radius = 1pt];}
    \draw [-to] (0pt,0pt) -- (8pt,0pt);
    \draw [-to] (8pt,0pt) -- (16pt,0pt);
    \draw [-to] (16pt,0pt) -- (24pt,0pt);
    \draw [-to] (24pt,0pt) -- (40pt,8pt);
  }
}

\newcommand{\doubleDeletionExample}{
  \tikz{
    \foreach \x in {0,8,16,24,32,40}{
      \fill (\x pt,0pt) circle [radius = 1pt];
      \fill (\x pt,8pt) circle [radius = 1pt];
      \fill (\x pt,16pt) circle [radius = 1pt];
    }
    \draw [-to] (0pt,0pt) -- (24pt,16pt);
    \draw [-to] (24pt,16pt) -- (32pt,16pt);
    \draw [-to] (32pt,16pt) -- (40pt,16pt);
  }
}

\newcommand{\subDelExample}{
  \tikz{
    \foreach \x in {0,8,16,24,32,40}{
      \fill (\x pt,0pt) circle [radius = 1pt];
      \fill (\x pt,8pt) circle [radius = 1pt];
      \fill (\x pt,16pt) circle [radius = 1pt];
    }
    \draw [-to] (0pt,0pt) -- (8pt,0pt);
    \draw [-to] (8pt,0pt) -- (16pt,8pt);
    \draw [-to] (16pt,8pt) -- (32pt,16pt);
    \draw [-to] (32pt,16pt) -- (40pt,16pt);
  }
}

\newcommand{\subSubExample}{
  \tikz{
    \foreach \x in {0,8,16,24,32,40}{
      \fill (\x pt,0pt) circle [radius = 1pt];
      \fill (\x pt,8pt) circle [radius = 1pt];
      \fill (\x pt,16pt) circle [radius = 1pt];
    }
    \draw [-to] (0pt,0pt) -- (8pt,0pt);
    \draw [-to] (8pt,0pt) -- (16pt,8pt);
    \draw [-to] (16pt,8pt) -- (24pt,16pt);
    \draw [-to] (24pt,16pt) -- (32pt,16pt);
    \draw [-to] (32pt,16pt) -- (40pt,16pt);
  }
}

\newcommand{\insertDeleteExample}{
  \tikz{
    \foreach \x in {0,8,16,24,32,40,48}{
      \fill (\x pt,0pt) circle [radius = 1pt];
      \fill (\x pt,8pt) circle [radius = 1pt];
      \fill (\x pt,16pt) circle [radius = 1pt];
    }
    \fill[white] (16pt,16pt) circle [radius = 1.2pt];
    \fill[white] (8pt,0pt) circle [radius = 1.2pt];
    \fill[white] (16pt,8pt) circle [radius = 1.2pt];
    \draw [-to] (0pt,0pt) -- (16pt,0pt);
    \draw [-to] (16pt,0pt) -- (8pt,8pt);
    \draw [-to] (8pt,8pt) -- (24pt,8pt);
    \draw [-to] (24pt,8pt) -- (40pt,16pt);
    \draw [-to] (40pt,16pt) -- (48pt,16pt);
  }
}

Each rule recognizes a specific type of edit. $\duparrow$ handles insertions, $\ddiagarrow$ handles substitutions and $\knightarrow$ handles deletions of one or more terminals. Let us consider some illustrative cases depicting the edit trajectory with specific Levenshtein alignments. Note that the trajectory may not be unique.

\begin{table}[H]
  \begin{tabular}{ccccccc}

    \texttt{f\hspace{3pt}.\hspace{3pt}\hlorange{[}\hspace{3pt}x\hspace{3pt})} &
    \texttt{f\hspace{3pt}.\hspace{3pt}\phantom{(}\hspace{3pt}x\hspace{3pt})} &
    \texttt{f\hspace{3pt}.\hspace{3pt}(\hspace{3pt}\hlred{x}\hspace{3pt})} &
    \texttt{\hlred{.}\hspace{3pt}\hlred{+}\hspace{3pt}(\hspace{3pt}x\hspace{3pt})} &
    \texttt{f\hspace{3pt}\hlorange{.}\hspace{3pt}\hlred{(}\hspace{3pt}x\hspace{3pt};} &
    \texttt{[\hspace{3pt}\hlorange{,}\hspace{3pt}\hlorange{x}\hspace{3pt}y\hspace{3pt}]} &
    \texttt{[\hspace{3pt}\phantom{,}\hspace{3pt},\hspace{3pt}\hlred{x}\hspace{3pt}y\hspace{3pt}]} \\

    \texttt{f\hspace{3pt}.\hspace{3pt}\hlorange{(}\hspace{3pt}x\hspace{3pt})} &
    \texttt{f\hspace{3pt}.\hspace{3pt}\hlgreen{(}\hspace{3pt}x\hspace{3pt})} &
    \texttt{f\hspace{3pt}.\hspace{3pt}(\hspace{3pt}\phantom{x}\hspace{3pt})} &
    \texttt{\phantom{f}\hspace{3pt}\phantom{.}\hspace{3pt}(\hspace{3pt}x\hspace{3pt})} &
    \texttt{f\hspace{3pt}\hlorange{*}\hspace{3pt}\phantom{(}\hspace{3pt}x\hspace{3pt};} &
    \texttt{[\hspace{3pt}\hlorange{x}\hspace{3pt}\hlorange{,}\hspace{3pt}y\hspace{3pt}]} &
    \texttt{[\hspace{3pt}\hlgreen{x}\hspace{3pt},\hspace{3pt}\phantom{x}\hspace{3pt}y\hspace{3pt}]} \\

    \substitutionExample & \insertionExample & \deletionExample & \doubleDeletionExample & \subDelExample & \subSubExample & \insertDeleteExample
  \end{tabular}
\end{table}

\section{The Bar-Hillel construction}

The Bar-Hillel construction is a method for conjoining a context-free grammar with a finite automaton. First proposed by Bar-Hillel in 1961, and later realized by Salomaa in 1973, this construction is based on the idea of a product automaton, generalized to a grammar. It consists of three rules:

\begin{prooftree}
  \AxiomC{$q \in I \phantom{\land} r \in F\vphantom{\overset{a}{\rightarrow}}$}
  \RightLabel{$\sqrt{\phantom{S}}$}
  \UnaryInfC{$\big(S\rightarrow q S r\big) \in P_\cap$}
  \DisplayProof
  \hskip 1em
  \AxiomC{$(A \rightarrow a) \in P$}
  \AxiomC{$(q\overset{a}{\rightarrow}r) \in \delta$}
  \RightLabel{$\uparrow$}
  \BinaryInfC{$\big(qAr\rightarrow a\big)\in P_\cap$}
\end{prooftree}

\begin{prooftree}
  \AxiomC{$(w \rightarrow xz) \in P\vphantom{\overset{a}{\rightarrow}}$}
  \AxiomC{$p,q,r \in Q$}
  \RightLabel{$\Join$}
  \BinaryInfC{$\big(pwr\rightarrow (pxq)(qzr)\big) \in P_\cap$}
\end{prooftree}

\subsection{State elimination}

The $\Join$ rule has a strong dependency on the number of states. So, the primary target is to first reduce the number of states in the Levenshtein automaton. We can reduce the number of states without compromising the integrity of the Bar-Hillel construction by pruning states which are obviously inaccessible. For example, let us consider the following scenario, where $G = S \rightarrow \texttt{( } S \texttt{ )} \mid \texttt{[ } S \texttt{ ]} \mid S \texttt{ + } S \mid \texttt{1}$ and $\err{\sigma} = \texttt{[ ( + ) ]}$. If we can establish $\mathcal{L}(\texttt{\_ \_ + ) ]}) = \varnothing \land \mathcal{L}(\texttt{\_ \_ \_ ) ]})\neq \varnothing$ and $\mathcal{L}(\texttt{[ ( + \_ \_}) = \varnothing \land \mathcal{L}(\texttt{[ ( \_ \_ \_})\neq\varnothing$, then:

\begin{figure}[H]
  \begin{center}
 \input{content/figures/pruned_lev3x5}
 \end{center}
\end{figure}

We can determine the monoedit bounds by conducting a binary search for the rightmost and leftmost states with an empty porous completion problem, and remove all states from the automaton which absorb trajectories that are incompatible. Similar bounds can be established for multi-edit locations.

Now, let us consider the Parikh constraints.

\subsection{Parikh refinements}

To identify superfluous $q, v, q'$ triples, we define an interval domain that soundly overapproximates the Parikh image, encoding the minimum and maximum number of terminals each nonterminal must and can generate, respectively. Since some intervals may be right-unbounded, we write $\mathbb{N}^*=\mathbb{N} \cup \{\infty\}$ to denote the upper bound, and $\Pi = \{[a, b] \in \mathbb{N} \times \mathbb{N}^* \mid a \leq b\}^{|\Sigma|}$ to denote the Parikh image of all terminals.

\begin{definition}{Parikh mapping of a nonterminal}{def:parikh}
Let $p: \Sigma^*\rightarrow\mathbb{N}^{|\Sigma|}$ be the Parikh operator~\cite{parikh1966context}, which counts the frequency of terminals in a string. We define the Parikh map as a function, $\pi: V \rightarrow \Pi$, returning the smallest interval such that $\forall \sigma: \Sigma^*, \forall v: V$, $v \Rightarrow^* \sigma \vdash p(\sigma) \in \pi(v)$.
\end{definition}

The Parikh mapping computes the greatest lower and least upper bound of the Parikh image over all strings in the language of a nonterminal. The infimum of a nonterminal's Parikh interval tells us how many of each terminal a nonterminal \textit{must} generate, and the supremum tells us how many it \textit{can} generate. Likewise, we define a similar relation over NFA state pairs:

\begin{definition}{Parikh mapping of NFA states}{}
  We define $\pi: Q\times Q \rightarrow \Pi$ as returning the smallest interval such that $\forall \sigma: \Sigma^*, \forall q, q': Q$, $q \overset{\sigma}{\Longrightarrow} q' \vdash p(\sigma) \in \pi(q, q')$.
\end{definition}

Next, we will define a measure on Parikh intervals representing the minimum total edits required to transform a string in one Parikh interval to a string in another, across all such pairings.

\begin{definition}{Parikh divergence}{}
  Given two Parikh intervals $\pi, \pi': \Pi$, we define the divergence between them as $\pi \parallel \pi' = \sum_{n=1}^{|\Sigma|} \min_{(i, i') \in \pi[n]\times \pi'[n]} |i - i'|$.
\end{definition}

We know that if the Parikh divergence between two intervals is nonzero, those intervals must be incompatible as no two strings, one from each Parikh interval, can be transformed into the other with fewer than $\pi \parallel \pi'$ edits.

\begin{definition}{Parikh compatibility}{}
  Let $q, q'$ be NFA states and $v$ be a CFG nonterminal. We call $\langle q, v, q'\rangle: Q\times V\times Q$ \textit{compatible} iff their divergence is zero, i.e., $v \lhd qq' \iff \big(\pi(v) \parallel \pi(q, q')\big) = 0$.
\end{definition}


For efficiency, Parikh compatibility can be precomputed for each $Q \times V \times Q$ triple and reused for each synthetic production. Finally, we are ready to define the modified Bar-Hillel construction:

\begin{definition}{Modified Bar-Hillel construction}{}
  Let $w, x, z$ be nonterminals in a CNF CFG and $p, q, r$ be states in an FSA. We modify the $\Join$ rule from the BH construction as follows:
\begin{prooftree}
%  \hskip -0.9em
%  \def\defaultHypSeparation{\hskip 0.14cm}
%  \AxiomC{$(A \rightarrow a) \in P$}
%  \AxiomC{$(q\overset{{\color{orange}[\cdot]}}{\rightarrow}r) \in \delta$}
%  \AxiomC{$\color{orange}a[\cdot]$}
%  \RightLabel{$\hat\uparrow$}
%  \TrinaryInfC{$\big(qAr\rightarrow a\big)\in P_\cap$}
%  \DisplayProof
  \AxiomC{$\vphantom{\overset{[\cdot]}{\rightarrow}}\color{orange} w \lhd pr \phantom{\land} x \lhd pq \phantom{\land} z \lhd qr$}
  \AxiomC{$(w \rightarrow xz) \in P\vphantom{\overset{a}{\rightarrow}}$}
  \AxiomC{$p,q,r \in Q$}
  \RightLabel{$\hat\Join$}
  \TrinaryInfC{$\big(pwr\rightarrow (pxq)(qzr)\big) \in P_\cap$}
\end{prooftree}
\end{definition}


Once constructed, we normalize $G_\cap$ by removing unreachable and non-generating productions~\cite{firsov2015certified} to obtain $G_\cap'$, which is a recognizer for the admissible set, i.e., $\mathcal{L}(G_\cap') = \ell_\cap$. Note, the original BH construction and our adapted version both reduce to the same CNF, $G_\cap'$, but normalization becomes significantly more tractable for large intersections, as far fewer useless productions are instantiated to only later be removed during normalization. This modified rule is not specific to Levenshtein automata and can be used to accelerate any FSA-CFG intersection.

\section{Matrix Bar-Hillel Construction}

A \textbf{Directed Graph (DG)} is a pair $\mathbf{G} = \langle V, E \subseteq V \times V\rangle$ whose structure can be described via its adjacency matrix $A[u, v] = \mathds{1}_E(u\rightarrow v)$. Powers of the adjacency matrix ($A^k$) represent the number of directed paths of a given length between any two nodes, i.e., $(A^k)[u,v] = |\{ p: V^k \mid p=u \rightarrow^* v\}|$. For a \textbf{Directed Acyclic Graph (DAG)}, $A$ satisfies the following properties:

\begin{enumerate}
\item $A^k = 0$ for all \( k \geq |V| \), since no path can visit the same node twice.
\item The reachability of $j$ from $i$ can be determined by examining the entries of $A^* = I + A + A^2 + \cdots + A^{n-1}$, where $I$ is the identity matrix.
\end{enumerate}

\noindent This can be restated as $\Tr(e^A) - |V| = 0$ as observed by Zheng et al.~\cite{zheng2018dags}.

Effectively, this matrix exponential is what we are computing when we are parsing. The parse matrix that is formed by:

\begin{equation}
  \exp(M) = M + M^2 + \cdots + M^{n-1}
\end{equation}

\noindent directly corresponds standard CYK parsing algorithm presented in \S~\ref{sec:matrix_parsing}. We will now generalize it to parsing an acyclic finite state automaton.

A \textbf{topological sort} of a graph $G$ is a total order on the vertices $(V, \prec)$ such that $u \rightarrow v \Longrightarrow u \prec v$. It can be easily shown that (1) DAGs are the only graphs which can be topologically sorted and (2) under such an ordering, the adjacency matrix of a DAG will be strictly upper triangular. One way to define a topsort is to repeatedly square the adjacency matrix using a $\langle \min, +\rangle$-semiring, then sort the vertices by incoming path length.

Let $A$ be an acyclic finite state automaton, and let $\prec_A: \langle \Sigma, Q, \delta, I, F\rangle$ be a topological sort on $\delta_A$. In other words, $(u \overset{s}{\rightarrow} v) \implies u \prec v$. We will now define a matrix algebra $(2^V, \oplus, \otimes)$ which we will use to decide intersection nonemptiness (INE) of a CFG and FSA. Let $G':\langle \Sigma, V, P, S\rangle$ be a CFG in CNF. We will reuse the definition for $\oplus = \cup$ and $\otimes$ from \S~\ref{sec:matrix_parsing}, and using the indices from the topological sort, initialize $M_0$ as follows:

\begin{equation}
M_0[u, v] = \{w : V \mid (u \overset{s}{\rightarrow} v) \in \delta \land (w \rightarrow s) \in P \}
\end{equation}

To avoid some unnecessary computation, we can define a helper function $\odot: Q \times Q \rightarrow 2^Q$ that returns the set of pivots on any path between two states in the FSA, i.e., $p\odot q = \{r \in Q \mid p \rightarrow^* r \rightarrow^* q \}$. Now, we are ready to define the elementwise fixpoint iteration:

\begin{equation}
  M^2[p, q] = \bigoplus_{r \in p \odot q} \big(M[p, r] \otimes M[r, q]\big)
\end{equation}

Finally, INE is decided by checking whether the parse matrix contains $S$ in any terminating state, i.e., $\big[S \in \bigcup_{q \in F}\exp(M_0)[0, q]\big] \Longleftrightarrow \mathcal{L}(G) \cap \mathcal{L}(A) \neq \varnothing$. This procedure takes roughly $\mathcal{O}(|Q|^2|P|)$ time and space, which confers a quadratic speedup over na\"ively generating the intersection grammar, then normalizing it to eliminate useless productions.